{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparatory work\n",
    "\n",
    "We first load the necessary backend and the necessary library for plot to work correctly and to to our computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\and√©ol\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from sklearn import mixture\n",
    "from scipy import stats\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "from spherecluster import VonMisesFisherMixture\n",
    "from spherecluster.von_mises_fisher_mixture import _movMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote here a function to read the Amerge.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(letter : str):\n",
    "\n",
    "    path = './Unistroke/'+letter+'merge.txt'\n",
    "    with open(path, 'r') as f:\n",
    "        nb_line = sum(1 for _ in f)\n",
    "    with open(path, 'r') as f:\n",
    "        data = np.zeros((nb_line,2))\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            data[i][0] = float(line.strip().split(\" \")[0])\n",
    "            data[i][1] = float(line.strip().split(\" \")[1])\n",
    "            i+=1\n",
    "        return data\n",
    "\n",
    "def read_and_merge(letter : str):\n",
    "    files = os.listdir('./Unistroke/')\n",
    "    regex = re.compile(r'^'+letter+'[0-9]')\n",
    "    files = list(filter(regex.search, files))\n",
    "    data = list()\n",
    "    for file in files:\n",
    "        with open(\"./Unistroke/\"+file) as content: \n",
    "            for line in content:\n",
    "                data.append((float(line.strip().split(\"\\t\")[0]),float(line.strip().split(\"\\t\")[1])))\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{1. Simulate a sample of size 500 of the following bivariate GMM :}$\n",
    "\n",
    "$$ 0.3 N( \\mu_1,\\Sigma_1)+ 0.7 N(\\mu_2,\\Sigma_2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = [-3,0]\n",
    "cov1 = [[5,-2],[-2,1]]\n",
    "\n",
    "mean2 = [3,0]\n",
    "cov2 = [[5,2],[2,2]]\n",
    "\n",
    "d1 = np.random.multivariate_normal(mean1, cov1, 500)\n",
    "d2 = np.random.multivariate_normal(mean2, cov2, 500)\n",
    "\n",
    "mixt = np.concatenate((d1,d2))\n",
    "\n",
    "\n",
    "plt.plot(mixt[:,0], mixt[:,1],\".\")\n",
    "plt.title('Simulated gaussian mixture')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the simulated gaussian mixture looks like the figures in the slides of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis: Gaussian model\n",
    "\n",
    "In this section, we analyse data coming from the Unistroke data set. \n",
    "We would like to know if a bivariate Gaussian mixture can make for a good representation of the letter A.\n",
    "\n",
    "We use the mixture package from the library sklearn to avoid implementing ourselves the EM algorithm for estimating parameters of a Gaussian mixture.\n",
    "\n",
    "$\\textbf{1. Estimate a bivariate GMM on the letter A data set and provide the estimated parameters.}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  We first read and plot the letter A data set after angular transformation. The transformation is the following :\n",
    "  \n",
    "  $$ x'_n = \\frac{x_{n+1}-x_n}{|x_{n+1}-x_n|}$$\n",
    "  \n",
    "  We understand why the data points appear on a circle using this transformation as $|x'_n|=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"A\")\n",
    "plt.figure()\n",
    "plt.plot(data[:,0], data[:,1],'.')\n",
    "plt.title('Merging of all A files after angular transformation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the estimation we use the function fit() from the gaussian\\_mixture\n",
    "package. The only parameter we define is the number of components of the Gaussian mixture, here n\\_components=2. The algorithm fits the model using an EM algorithm for Gaussian mixtures.\n",
    "The stopping criterion is reached when the change of likelihood between two iteration is less than $\\textbf{tol}$. The maximum number of iteration is $\\textbf{max_iter}$. The initialisation process is assured internally by the method \\_initialize\\_parameters(self , X, random\\_state). We can see in this method that the initialisation process can be done using the k-mean algorithm or using random initial parameters. by default it will use a k-mean algorithm.\n",
    "We chose to let every parameters set as the default ones.\n",
    "We chose here to let the full freedom to the covariance matrices (option full).\n",
    "The algorithm return the following estimated parameters for our data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means :  [[-0.36571287  0.9060224 ]\n",
      " [-0.29510373 -0.72483125]]\n",
      "\n",
      "\n",
      "covs :  [[[0.03903012 0.01426564]\n",
      "  [0.01426564 0.00634938]]\n",
      "\n",
      " [[0.27188755 0.0823439 ]\n",
      "  [0.0823439  0.1156479 ]]]\n"
     ]
    }
   ],
   "source": [
    "#EM algorithm for gaussian mixtures\n",
    "gmm = mixture.GaussianMixture(2,covariance_type='full')\n",
    "gmm.fit(data)\n",
    "print(\"means : \",gmm.means_)\n",
    "print(\"\\n\")\n",
    "print(\"covs : \",gmm.covariances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained are the means and the covariance matrices of each of our 2 estimated Gaussian after the EM algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{2. Label the data using the estimated model and show the pdf of the estimated GMM}$\n",
    "\n",
    "To label the data we use the method predict from the Gaussian mixture.\n",
    "The predict method use the fitted parameters from the function fit to estimate the probability of each data point to belong to one cluster or the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# meshgrid\n",
    "labels = gmm.predict(data)\n",
    "x = np.linspace(-2,2,500)\n",
    "X,Y = np.meshgrid(x,x)\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "# pdf\n",
    "rv = stats.multivariate_normal(gmm.means_[0],gmm.covariances_[0])\n",
    "rv2 = stats.multivariate_normal(gmm.means_[1],gmm.covariances_[1])\n",
    "# color with classification\n",
    "bool_label= list(map(bool,labels))\n",
    "inv_bool_label = [not i for i in bool_label]  \n",
    "data1 = data[bool_label]\n",
    "data2 = data[inv_bool_label]\n",
    "# plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4),constrained_layout=True)\n",
    "\n",
    "axs[0].contourf(X,Y,rv.pdf(pos))\n",
    "axs[0].plot(data1[:,0], data1[:,1],'.', color='g')\n",
    "axs[0].plot(data2[:,0], data2[:,1],'.', color='b')\n",
    "axs[0].set_title('fitted distribution of blue data points')\n",
    "axs[0].set_xlabel('x')\n",
    "axs[0].set_ylabel('y')\n",
    "\n",
    "axs[1].contourf(X,Y,rv2.pdf(pos))\n",
    "axs[1].plot(data1[:,0], data1[:,1],'.', color='g')\n",
    "axs[1].plot(data2[:,0], data2[:,1],'.', color='b')\n",
    "axs[1].set_title('fitted distribution of green data points')\n",
    "axs[1].set_xlabel('x')\n",
    "axs[1].set_ylabel('y')\n",
    "\n",
    "fig.suptitle('classification of data points and \\n gaussian pdf estimated by the EM algorithm',fontsize=15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{3 (a) : Plot each marginal histogram and add the estimated mixture of univariate\n",
    "Gaussian pdfs to the figure.}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs2 = plt.subplots(1, 2, figsize=(8, 4),constrained_layout=True)\n",
    "\n",
    "axs2[0].hist(data[:,0],150,  density = True)\n",
    "axs2[1].hist(data[:,1],150,  density = True)\n",
    "\n",
    "mg = stats.norm(gmm.means_[0,0], gmm.covariances_[0,0,0])\n",
    "mg2 = stats.norm(gmm.means_[0,1], gmm.covariances_[0,1,1])\n",
    "mg3 = stats.norm(gmm.means_[1,0], gmm.covariances_[1,0,0])\n",
    "mg4 = stats.norm(gmm.means_[1,1], gmm.covariances_[1,1,1])\n",
    "\n",
    "axs2[0].plot(x,(mg.pdf(x)+mg3.pdf(x))*0.5)\n",
    "axs2[1].plot(x,(mg2.pdf(x)+mg4.pdf(x))*0.5)\n",
    "axs2[0].set_title('marginal along x')\n",
    "axs2[1].set_title('marginal along y')\n",
    "\n",
    "axs2[0].set_xlabel('x')\n",
    "axs2[0].set_ylabel('density')\n",
    "axs2[1].set_xlabel('y')\n",
    "axs2[1].set_ylabel('density')\n",
    "\n",
    "fig2.suptitle('marginal histograms and marginal \\n estimated gaussian mixtures',fontsize=15)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\textbf{3. (b) For each marginal, provide separate histograms of each cluster and add the estimated\n",
    " Gaussian pdf to the figure.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'cls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1e326338ad8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mfig3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'marginal estimated pdf and histogram for each cluster '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mfig3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'cls'"
     ]
    }
   ],
   "source": [
    "fig3, axs3 = plt.subplots(2, 2, figsize=(8, 4),constrained_layout=True)\n",
    "bar_num = 40\n",
    "axs3[0][0].hist(data1[:,0],bar_num,  density = True,color='g')\n",
    "axs3[0][0].plot(x,(mg3.pdf(x)),color='r')\n",
    "axs3[0][0].set_title('marginal along x, green cluster')\n",
    "\n",
    "axs3[0][1].hist(data1[:,1], bar_num,  density = True,color='g')\n",
    "axs3[0][1].plot(x,(mg4.pdf(x)),color='r')\n",
    "axs3[0][1].set_title('marginal along y, green cluster')\n",
    "\n",
    "axs3[1][0].hist(data2[:,0],bar_num,  density = True,color='b')\n",
    "axs3[1][0].plot(x,(mg.pdf(x)),color='r')\n",
    "axs3[1][0].set_title('marginal along x, blue cluster')\n",
    "\n",
    "axs3[1][1].hist(data2[:,1],bar_num,  density = True,color='b')\n",
    "axs3[1][1].plot(x,(mg2.pdf(x)),color='r')\n",
    "axs3[1][1].set_title('marginal along y, blue cluster')\n",
    "\n",
    "axs3[0][0].set_xlabel('x')\n",
    "axs3[0][0].set_ylabel('density')\n",
    "axs3[1][0].set_xlabel('x')\n",
    "axs3[1][0].set_ylabel('density')\n",
    "axs3[0][1].set_xlabel('y')\n",
    "axs3[0][1].set_ylabel('density')\n",
    "axs3[1][1].set_xlabel('y')\n",
    "axs3[1][1].set_ylabel('density')\n",
    "\n",
    "\n",
    "fig3.suptitle('marginal estimated pdf and histogram for each cluster ',fontsize=15)\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Plot each data point x i with some colourmap corresponding to}$ $P(Z_i = 1|X_i )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_proba=gmm.predict_proba(data)\n",
    "plt.scatter(data[:,0], data[:,1], c=np.log(posterior_proba[:,0]))\n",
    "plt.title('data points given posterior probability')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute $P(Z_i = 1|X_i )$, we use the predict_proba() function. It returns for each fitted gaussian the probability of each data points to be generated by the said Gaussian. This can be interpreted as a \"soft\" or continuous labelling of the data points. We see on the plot above a clear dichotomy between two sets of data points corresponding to the two different labelled clusters. This was the expected results. Using the log of the posterior probability helps for visualisation as the transition between the two cluster is too \"sharp\" without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gmm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7cd83bb5933e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mposterior_proba\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposterior_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data points given posterior probability'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gmm' is not defined"
     ]
    }
   ],
   "source": [
    "posterior_proba=gmm.predict_proba(data)\n",
    "plt.scatter(data[:,0], data[:,1], c=posterior_proba[:,0])\n",
    "plt.title('data points given posterior probability')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 2 / Mandatory Additionnal Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1.2.1  This function transform Unistroke to Angular data\n",
    "\n",
    "def unistroke_to_angular(uni_data):\n",
    "    nb_lines = len(uni_data)\n",
    "    ang_data = np.zeros((nb_lines, 2))\n",
    "    ang_data = np.zeros((nb_lines, 2))\n",
    "    for index in range(nb_lines):\n",
    "        ang_data[index][0] = np.sqrt(uni_data[index][0] ** 2 + uni_data[index][1] ** 2)\n",
    "        if uni_data[index][0] != 0:\n",
    "            ang_data[index][1] = np.arctan(uni_data[index][1] / uni_data[index][0])\n",
    "        else:\n",
    "            ang_data[index][1] = np.pi / 2\n",
    "    return ang_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the input data\n",
    "uni_data = read_data('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform to angular data\n",
    "ang_data = unistroke_to_angular(uni_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angular data histograms\n",
    "plt.hist(ang_data[:, 0], 150)\n",
    "plt.hist(ang_data[:, 1], 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just above is the histogram of the angle of the translated data. We can see that all radius are set to one, which can be explained by the fact that our A is represented by a circle, so all point are equidistant to the figure's center. \n",
    "Therefore a Von Mises mixture is more fitted t othe study as we have only one histogram to study (angles) instead of the two provided by Cartesian coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.2\n",
    "\n",
    "Von Mises Law allows to approximate the circular normal distribution law. It is adapted to plot a distribution of a theta variable moving around a circle.\n",
    "\n",
    "A Von Mises mixture will be a mixture as defined in the lectures where the family of distributions is only composed of Von mises distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.3\n",
    "\n",
    "Our study data set represents an A as a circle. Therefore a mixture of Von mises will be a better fit, as it is adapted to approximate circular distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.5\n",
    "\n",
    "# Von Mises mixture fit with AMerge data, parameters\n",
    "\n",
    "mix = VonMisesFisherMixture(2)\n",
    "mix = mix.fit(ang_data)\n",
    "#params examples : mix.weights_, mix.cluster_centers_, mix.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the estimated parameters\n",
    "params = _movMF(ang_data, 2)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-acc16d48019d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Color the data with the estimated labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#Color the data with the estimated labels\n",
    "x = [ang_data[i][0] for i in range(len(ang_data))]\n",
    "y = [ang_data[i][1] for i in range(len(ang_data))]\n",
    "plt.scatter(x, y, c=mix.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
